{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "079ffb92",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-24T05:00:28.842597Z",
     "iopub.status.busy": "2024-04-24T05:00:28.842200Z",
     "iopub.status.idle": "2024-04-24T05:00:30.065741Z",
     "shell.execute_reply": "2024-04-24T05:00:30.064589Z"
    },
    "papermill": {
     "duration": 1.233778,
     "end_time": "2024-04-24T05:00:30.068521",
     "exception": false,
     "start_time": "2024-04-24T05:00:28.834743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/tmnist-alphabet-94-characters/94_character_TMNIST.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e28432b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T05:00:30.081586Z",
     "iopub.status.busy": "2024-04-24T05:00:30.081051Z",
     "iopub.status.idle": "2024-04-24T05:00:52.187971Z",
     "shell.execute_reply": "2024-04-24T05:00:52.186773Z"
    },
    "papermill": {
     "duration": 22.116638,
     "end_time": "2024-04-24T05:00:52.190882",
     "exception": false,
     "start_time": "2024-04-24T05:00:30.074244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 05:00:38.956429: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-24 05:00:38.956616: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-24 05:00:39.163045: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, ReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95895ceb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T05:00:52.205041Z",
     "iopub.status.busy": "2024-04-24T05:00:52.203641Z",
     "iopub.status.idle": "2024-04-24T05:00:52.209621Z",
     "shell.execute_reply": "2024-04-24T05:00:52.208605Z"
    },
    "papermill": {
     "duration": 0.015647,
     "end_time": "2024-04-24T05:00:52.212314",
     "exception": false,
     "start_time": "2024-04-24T05:00:52.196667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128 # How many independent images should we process in parallel.\n",
    "n_hidden = 128 # Define the number of hidden layers in dense neural net layer.\n",
    "max_iters = 10000 # Number of training iterations of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3a9f895",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T05:00:52.225256Z",
     "iopub.status.busy": "2024-04-24T05:00:52.224884Z",
     "iopub.status.idle": "2024-04-24T05:01:42.512744Z",
     "shell.execute_reply": "2024-04-24T05:01:42.511594Z"
    },
    "papermill": {
     "duration": 50.303091,
     "end_time": "2024-04-24T05:01:42.521031",
     "exception": false,
     "start_time": "2024-04-24T05:00:52.217940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>labels</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Salsa-Regular</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MouseMemoirs-Regular</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creepster-Regular</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SeoulNamsan-Light</td>\n",
       "      <td>/</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HachiMaruPop-Regular</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  names labels    1    2    3    4    5    6    7    8  ...  \\\n",
       "0         Salsa-Regular      6  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "1  MouseMemoirs-Regular      D  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "2     Creepster-Regular      f  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "3     SeoulNamsan-Light      /  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "4  HachiMaruPop-Regular      F  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "   775  776  777  778  779  780  781  782  783  784  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 786 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv(\"/kaggle/input/tmnist-alphabet-94-characters/94_character_TMNIST.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a1153cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T05:01:42.534997Z",
     "iopub.status.busy": "2024-04-24T05:01:42.534016Z",
     "iopub.status.idle": "2024-04-24T05:01:44.002182Z",
     "shell.execute_reply": "2024-04-24T05:01:44.001146Z"
    },
    "papermill": {
     "duration": 1.477936,
     "end_time": "2024-04-24T05:01:44.004791",
     "exception": false,
     "start_time": "2024-04-24T05:01:42.526855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# input(X) and output labels(y)\n",
    "\n",
    "# Dividing by 255 to normalize the data bring to the range(0, 1)\n",
    "X=df.drop(['names','labels'],axis=1).values.reshape(df.shape[0], 1, 28, 28) / 255\n",
    "y=df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36ae0750",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T05:01:44.020899Z",
     "iopub.status.busy": "2024-04-24T05:01:44.020451Z",
     "iopub.status.idle": "2024-04-24T05:01:44.141623Z",
     "shell.execute_reply": "2024-04-24T05:01:44.140394Z"
    },
    "papermill": {
     "duration": 0.131347,
     "end_time": "2024-04-24T05:01:44.144300",
     "exception": false,
     "start_time": "2024-04-24T05:01:44.012953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(df['labels'].unique()))\n",
    "vocab_size = len(chars) # Number of unique characters in the input.\n",
    "\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "\n",
    "# Map the labels for string to integer.\n",
    "y_upd = np.array([stoi[ch] for ch in y])\n",
    "\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec210c53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T05:01:44.158638Z",
     "iopub.status.busy": "2024-04-24T05:01:44.158220Z",
     "iopub.status.idle": "2024-04-24T05:01:46.843989Z",
     "shell.execute_reply": "2024-04-24T05:01:46.842830Z"
    },
    "papermill": {
     "duration": 2.696288,
     "end_time": "2024-04-24T05:01:46.846886",
     "exception": false,
     "start_time": "2024-04-24T05:01:44.150598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_upd, test_size = 0.2, random_state = 1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbdde1f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T05:01:46.860953Z",
     "iopub.status.busy": "2024-04-24T05:01:46.860576Z",
     "iopub.status.idle": "2024-04-24T05:01:47.010874Z",
     "shell.execute_reply": "2024-04-24T05:01:47.009937Z"
    },
    "papermill": {
     "duration": 0.160547,
     "end_time": "2024-04-24T05:01:47.013565",
     "exception": false,
     "start_time": "2024-04-24T05:01:46.853018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the data to torch tensors\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "\n",
    "# Convert the label data to one hot encoding vectors.\n",
    "y_train_one_hot = F.one_hot(torch.from_numpy(y_train), num_classes=vocab_size)\n",
    "y_test_one_hot = F.one_hot(torch.from_numpy(y_test), num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8422c99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T05:01:47.029842Z",
     "iopub.status.busy": "2024-04-24T05:01:47.029361Z",
     "iopub.status.idle": "2024-04-24T05:01:47.037876Z",
     "shell.execute_reply": "2024-04-24T05:01:47.036472Z"
    },
    "papermill": {
     "duration": 0.019847,
     "end_time": "2024-04-24T05:01:47.040723",
     "exception": false,
     "start_time": "2024-04-24T05:01:47.020876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get batch_size rows of train/test data for their respective purposes.\n",
    "def get_batch(split):\n",
    "    X_c = X_train if split == \"train\" else X_test\n",
    "    y_c = y_train_one_hot if split == \"train\" else y_test_one_hot\n",
    "    ix = torch.randint(len(X_c), (batch_size, ))\n",
    "    x_batch = torch.tensor(torch.stack([X_c[i] for i in ix], dim=0), dtype=torch.float32)\n",
    "    y_batch = torch.tensor(torch.stack([y_c[i] for i in ix], dim=0), dtype=torch.float32)\n",
    "    return x_batch.to(device), y_batch.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1de86b79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T05:01:47.055346Z",
     "iopub.status.busy": "2024-04-24T05:01:47.054747Z",
     "iopub.status.idle": "2024-04-24T05:01:47.063778Z",
     "shell.execute_reply": "2024-04-24T05:01:47.062498Z"
    },
    "papermill": {
     "duration": 0.019334,
     "end_time": "2024-04-24T05:01:47.066197",
     "exception": false,
     "start_time": "2024-04-24T05:01:47.046863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Estimate the loss of the model on a small slice of test set(batch_size(128) rows).\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    x_t, y_t = get_batch(\"test\")\n",
    "    for inp, label in zip(x_t, y_t):\n",
    "        inp = inp.view(1, -1, inp.shape[1], inp.shape[2])\n",
    "        out = model(inp)\n",
    "        predicted = torch.argmax(out, dim=1)\n",
    "        label_predicted = torch.argmax(label)\n",
    "        correct += (predicted==label_predicted).sum().item()\n",
    "    total = y_t.shape[0]\n",
    "    accuracy = correct * 100.0 / total\n",
    "    model.train()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7659764b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T05:01:47.080561Z",
     "iopub.status.busy": "2024-04-24T05:01:47.079852Z",
     "iopub.status.idle": "2024-04-24T05:01:47.126219Z",
     "shell.execute_reply": "2024-04-24T05:01:47.124944Z"
    },
    "papermill": {
     "duration": 0.056627,
     "end_time": "2024-04-24T05:01:47.128911",
     "exception": false,
     "start_time": "2024-04-24T05:01:47.072284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3), # (B, 1, 28, 28) --> (B, 32, 26, 26)\n",
    "            nn.ReLU(), # (B, 32, 26, 26) --> (B, 32, 26, 26)\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3), # (B, 32, 26, 26) --> (B, 64, 24, 24)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # (B, 64, 24, 24) --> (B, 64, 12, 12)\n",
    "            nn.Flatten(start_dim=1, end_dim=-1), # (B, 64, 12, 12) --> (B, 64 * 12 * 12)\n",
    "            nn.Linear(64 * 12 * 12, n_hidden), # (B, 9216) --> (B, n_hidden)\n",
    "            nn.BatchNorm1d(n_hidden), # Applied batch norm to make the model more resilient.\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, vocab_size), # (B, n_hidden) --> (B, vocab_size)\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "model = ConvNet()\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6ce9dac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T05:01:47.142969Z",
     "iopub.status.busy": "2024-04-24T05:01:47.142550Z",
     "iopub.status.idle": "2024-04-24T05:24:30.218451Z",
     "shell.execute_reply": "2024-04-24T05:24:30.217541Z"
    },
    "papermill": {
     "duration": 1363.085966,
     "end_time": "2024-04-24T05:24:30.221160",
     "exception": false,
     "start_time": "2024-04-24T05:01:47.135194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/434405513.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_batch = torch.tensor(torch.stack([X_c[i] for i in ix], dim=0), dtype=torch.float32)\n",
      "/tmp/ipykernel_19/434405513.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(torch.stack([y_c[i] for i in ix], dim=0), dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, train loss: 4.6321, test accuracy: 1.5625%\n",
      "step: 500, train loss: 0.5139, test accuracy: 96.0938%\n",
      "step: 1000, train loss: 0.2690, test accuracy: 90.6250%\n",
      "step: 1500, train loss: 0.2987, test accuracy: 95.3125%\n",
      "step: 2000, train loss: 0.1965, test accuracy: 92.9688%\n",
      "step: 2500, train loss: 0.1960, test accuracy: 88.2812%\n",
      "step: 3000, train loss: 0.1931, test accuracy: 91.4062%\n",
      "step: 3500, train loss: 0.1694, test accuracy: 90.6250%\n",
      "step: 4000, train loss: 0.1188, test accuracy: 92.1875%\n",
      "step: 4500, train loss: 0.1274, test accuracy: 93.7500%\n",
      "step: 5000, train loss: 0.1314, test accuracy: 91.4062%\n",
      "step: 5500, train loss: 0.1383, test accuracy: 96.8750%\n",
      "step: 6000, train loss: 0.1761, test accuracy: 90.6250%\n",
      "step: 6500, train loss: 0.0947, test accuracy: 89.8438%\n",
      "step: 7000, train loss: 0.1443, test accuracy: 93.7500%\n",
      "step: 7500, train loss: 0.0544, test accuracy: 92.9688%\n",
      "step: 8000, train loss: 0.0983, test accuracy: 95.3125%\n",
      "step: 8500, train loss: 0.0828, test accuracy: 92.1875%\n",
      "step: 9000, train loss: 0.1320, test accuracy: 96.8750%\n",
      "step: 9500, train loss: 0.0898, test accuracy: 94.5312%\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 3e-4)\n",
    "\n",
    "for i in range(max_iters):\n",
    "    xb, yb = get_batch(\"train\")\n",
    "    logits = model(xb)\n",
    "    loss = F.cross_entropy(logits, yb)\n",
    "    \n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (i % 500 == 0):\n",
    "        accuracy = estimate_loss()\n",
    "        print(f\"step: {i}, train loss: {loss:.4f}, test accuracy: {accuracy:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c5e862b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T05:24:30.240723Z",
     "iopub.status.busy": "2024-04-24T05:24:30.238755Z",
     "iopub.status.idle": "2024-04-24T05:28:15.961418Z",
     "shell.execute_reply": "2024-04-24T05:28:15.959934Z"
    },
    "papermill": {
     "duration": 225.743536,
     "end_time": "2024-04-24T05:28:15.972851",
     "exception": false,
     "start_time": "2024-04-24T05:24:30.229315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/2336300992.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_t, y_t = torch.tensor(X_train, dtype=torch.float32).to(device), y_train_one_hot.to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the entire test set: 97.00%\n"
     ]
    }
   ],
   "source": [
    "# Loss on the entire test set. \n",
    "# Accuracy comes to 96.82%\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    x_t, y_t = torch.tensor(X_train, dtype=torch.float32).to(device), y_train_one_hot.to(device)\n",
    "    for inp, label in zip(x_t, y_t):\n",
    "        inp = inp.view(1, -1, inp.shape[1], inp.shape[2])\n",
    "        out = model(inp)\n",
    "        predicted = torch.argmax(out, dim=1)\n",
    "        label_predicted = torch.argmax(label)\n",
    "        correct += (predicted==label_predicted).sum().item()\n",
    "    total = y_t.shape[0]\n",
    "    accuracy = correct * 100.0 / total\n",
    "    model.train()\n",
    "    print(f\"Accuracy on the entire test set: {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1564532,
     "sourceId": 2830968,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30684,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1673.268968,
   "end_time": "2024-04-24T05:28:18.779572",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-24T05:00:25.510604",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
